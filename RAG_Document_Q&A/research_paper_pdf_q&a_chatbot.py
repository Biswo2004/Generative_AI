import streamlit as st
import os
import time
import tempfile
from datetime import datetime
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import create_retrieval_chain
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader
import speech_recognition as sr
from gtts import gTTS
import base64
from io import BytesIO

# ЁЯМ▒ Load environment variables
load_dotenv()
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")

# ЁЯОи Page config
st.set_page_config(page_title="RAG Chatbot", page_icon="ЁЯУЪ", layout="wide")

# ------------------------------
# ЁЯМЯ Sidebar UI & Groq API Key
# ------------------------------
st.markdown("""
<style>
[data-testid="stSidebar"] {
    background: linear-gradient(to right, #FF512F, #DD2476);
    color: white;
}
[data-testid="stSidebar"] .stTextInput>div>div>input {
    background-color: rgba(255,255,255,0.95);
    color: black;
    border-radius: 8px;
    padding: 8px;
}
.stButton>button {
    background: linear-gradient(to right, #FF512F, #DD2476);
    color: white;
    font-weight: bold;
    border-radius: 10px;
    padding: 12px 24px;
}
.stButton>button:hover {
    background: linear-gradient(to right, #DD2476, #FF512F);
    color: black;
}
</style>
""", unsafe_allow_html=True)

groq_api_key = st.sidebar.text_input("ЁЯФС Enter your Groq API Key", type="password")
if not groq_api_key:
    st.info("Please enter the Groq API Key to proceed.")
    st.stop()
elif not groq_api_key.startswith("gsk_"):
    st.warning("тЭМ Invalid Groq API Key. Must start with 'gsk_'.")
    st.stop()
else:
    os.environ["GROQ_API_KEY"] = groq_api_key

# ------------------------------
# ЁЯМН Language Toggle
# ------------------------------
language = st.sidebar.selectbox("ЁЯМР Choose Language", ["English", "рд╣рд┐рдиреНрджреА"])

TEXT = {
    "English": {
        "title": "ЁЯУЪ Research Paper Q&A Chatbot",
        "subtitle": "Ask questions based on your uploaded research papers.",
        "upload": "ЁЯУБ Upload your research papers (PDF only)",
        "query": "ЁЯФН Enter your query from the research papers:",
        "search": "ЁЯЪА Search",
        "response": "тЬЕ Response",
        "similarity": "ЁЯУД Document similarity search",
        "footer": "Made with тЭдя╕П by Biswojit Bal | Powered by Groq & OpenAI",
        "upload_warning": "тЪая╕П Please upload at least one PDF to begin.",
        "query_warning": "тЪая╕П Please enter a query before searching.",
        "embedding_success": "тЬЕ Vector embeddings created successfully.",
        "embedding_error": "тЭМ Error creating embeddings:",
        "retrieval_error": "тЭМ Error during retrieval or generation:",
        "model_error": "тЭМ Failed to initialize Groq model:",
        "clear_history": "ЁЯз╣ Clear Chat History",
        "speak": "ЁЯФК Speak Response"
    },
    "рд╣рд┐рдиреНрджреА": {
        "title": "ЁЯУЪ рд╢реЛрдз рдкрддреНрд░ рдкреНрд░рд╢реНрдиреЛрддреНрддрд░ рдЪреИрдЯрдмреЙрдЯ",
        "subtitle": "рдЕрдкрдиреЗ рдЕрдкрд▓реЛрдб рдХрд┐рдП рдЧрдП рд╢реЛрдз рдкрддреНрд░реЛрдВ рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рдкреНрд░рд╢реНрди рдкреВрдЫреЗрдВред",
        "upload": "ЁЯУБ рдЕрдкрдиреЗ рд╢реЛрдз рдкрддреНрд░ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ (рдХреЗрд╡рд▓ PDF)",
        "query": "ЁЯФН рд╢реЛрдз рдкрддреНрд░реЛрдВ рд╕реЗ рдЕрдкрдирд╛ рдкреНрд░рд╢реНрди рджрд░реНрдЬ рдХрд░реЗрдВ:",
        "search": "ЁЯЪА рдЦреЛрдЬреЗрдВ",
        "response": "тЬЕ рдЙрддреНрддрд░",
        "similarity": "ЁЯУД рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рд╕рдорд╛рдирддрд╛ рдЦреЛрдЬ",
        "footer": "тЭдя╕П рд╕реЗ рдмрдирд╛рдпрд╛ рдЧрдпрд╛ Biswojit Bal рджреНрд╡рд╛рд░рд╛ | Groq рдФрд░ OpenAI рджреНрд╡рд╛рд░рд╛ рд╕рдВрдЪрд╛рд▓рд┐рдд",
        "upload_warning": "тЪая╕П рдХреГрдкрдпрд╛ рд╢реБрд░реВ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдХрдо рд╕реЗ рдХрдо рдПрдХ PDF рдЕрдкрд▓реЛрдб рдХрд░реЗрдВред",
        "query_warning": "тЪая╕П рдХреГрдкрдпрд╛ рдЦреЛрдЬрдиреЗ рд╕реЗ рдкрд╣рд▓реЗ рдПрдХ рдкреНрд░рд╢реНрди рджрд░реНрдЬ рдХрд░реЗрдВред",
        "embedding_success": "тЬЕ рд╡реЗрдХреНрдЯрд░ рдПрдореНрдмреЗрдбрд┐рдВрдЧ рд╕рдлрд▓рддрд╛рдкреВрд░реНрд╡рдХ рдмрдирд╛рдИ рдЧрдИред",
        "embedding_error": "тЭМ рдПрдореНрдмреЗрдбрд┐рдВрдЧ рдмрдирд╛рддреЗ рд╕рдордп рддреНрд░реБрдЯрд┐:",
        "retrieval_error": "тЭМ рдкреБрдирдГ рдкреНрд░рд╛рдкреНрддрд┐ рдпрд╛ рдЙрддреНрддрд░ рдирд┐рд░реНрдорд╛рдг рдореЗрдВ рддреНрд░реБрдЯрд┐:",
        "model_error": "тЭМ Groq рдореЙрдбрд▓ рдкреНрд░рд╛рд░рдВрдн рдХрд░рдиреЗ рдореЗрдВ рд╡рд┐рдлрд▓:",
        "clear_history": "ЁЯз╣ рдЪреИрдЯ рдЗрддрд┐рд╣рд╛рд╕ рд╕рд╛рдлрд╝ рдХрд░реЗрдВ",
        "speak": "ЁЯФК рдЙрддреНрддрд░ рд╕реБрдиреЗрдВ"
    }
}

# ------------------------------
# ЁЯОи Main UI Styling
# ------------------------------
st.markdown("""
<style>
body {
    background: linear-gradient(to right, #FDEB71, #F8D800);
    font-family: 'Poppins', sans-serif;
}
h1 {
    background: -webkit-linear-gradient(#FF512F, #DD2476);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    font-size: 42px;
}
h2 {
    color: #DD2476;
}
.response-card {
    background: linear-gradient(to right, #FF512F, #DD2476);
    color: white;
    padding: 15px;
    border-radius: 12px;
    font-size: 16px;
}

/* Drag & Drop area gradient (keep text normal) */
.stFileUploader > div {
    background: linear-gradient(to right, #36D1DC, #5B86E5);
    padding: 12px;
    border-radius: 12px;
    transition: all 0.3s ease;
}

/* Hover effect for the box */
.stFileUploader > div:hover {
    background: linear-gradient(to right, #5B86E5, #36D1DC);
    box-shadow: 0 4px 15px rgba(0,0,0,0.2);
}

/* ЁЯФ╣ Text Area Gradient */
.stTextArea>div>div>textarea {
    background: linear-gradient(to right, #FF9A9E, #FAD0C4);
    color: white;
    border-radius: 12px;
    padding: 12px;
    font-weight: bold;
    transition: all 0.3s ease;
}
.stTextArea>div>div>textarea:hover,
.stTextArea>div>div>textarea:focus {
    background: linear-gradient(to right, #FAD0C4, #FF9A9E);
    color: black;
    box-shadow: 0 4px 15px rgba(0,0,0,0.2);
}
.stTextArea>div>div>textarea::placeholder {
    color: #f1f1f1;
    opacity: 0.9;
}

/* ЁЯФ╣ Footer Gradient matching button */
.footer {
    text-align: center;
    padding: 12px;
    color: white;
    background: linear-gradient(to right, #FF512F, #DD2476);
    border-radius: 12px;
    margin-top: 20px;
    font-weight: bold;
}
</style>
""", unsafe_allow_html=True)

# ------------------------------
# Title & Subtitle
# ------------------------------
st.markdown(f"""
<div style="
    background: linear-gradient(to right, #FF512F, #DD2476);
    padding: 25px;
    border-radius: 16px;
    text-align: center;
">
    <h1 style='margin:0; font-size:42px; font-weight:bold;
               background: linear-gradient(to right, #a1c4fd, #c2e9fb);
               -webkit-background-clip: text; 
               -webkit-text-fill-color: transparent;
               '>{TEXT[language]['title']}</h1>
    <p style='margin:5px 0 0 0; font-size:18px; font-style:italic;
              background: linear-gradient(to right, #a1c4fd, #c2e9fb);
              -webkit-background-clip: text;
              -webkit-text-fill-color: transparent;
              '>{TEXT[language]['subtitle']}</p>
</div>
""", unsafe_allow_html=True)

temperature = st.slider("ЁЯОЫя╕П Response creativity", 0.0, 1.0, 0.7)

# ЁЯФР Groq LLM Init
try:
    llm = ChatGroq(model="llama3-8b-8192", temperature=temperature)
except Exception as e:
    st.error(f"{TEXT[language]['model_error']} {e}")
    st.stop()

prompt = ChatPromptTemplate.from_template("""
You are a helpful assistant that answers questions based on the provided documents.
Answer the question to the best of your ability based on the context provided in the documents.
If you do not know the answer, say "I don't know".

<context>{context}</context>
Question: {input}
""")

uploaded_files = st.file_uploader(TEXT[language]["upload"], type=["pdf"], accept_multiple_files=True)

# ------------------------------
# Vector Embeddings
# ------------------------------
def create_vector_embeddings():
    try:
        st.session_state.embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
        documents = []
        for uploaded_file in uploaded_files:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_file.read())
                tmp_file_path = tmp_file.name
            loader = PyPDFLoader(tmp_file_path)
            documents.extend(loader.load())
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        final_docs = text_splitter.split_documents(documents)
        st.session_state.vector_store = FAISS.from_documents(final_docs, st.session_state.embeddings)
        st.success(TEXT[language]["embedding_success"])
    except Exception as e:
        st.error(f"{TEXT[language]['embedding_error']} {e}")
        st.stop()

# ------------------------------
# Session State
# ------------------------------
if "user_prompt" not in st.session_state:
    st.session_state.user_prompt = ""
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "last_answer" not in st.session_state:
    st.session_state.last_answer = ""

# ------------------------------
# User Input
# ------------------------------
user_prompt = st.text_area(TEXT[language]["query"], value=st.session_state.user_prompt, height=100)

# ------------------------------
# ЁЯОЩя╕П Voice Input
# ------------------------------
st.markdown("### ЁЯОд Voice Input (Optional)")
if st.button("ЁЯОЩя╕П Speak Your Question"):
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        st.info("ЁЯОз Listening... Please speak clearly.")
        audio = recognizer.listen(source)

    try:
        voice_query = recognizer.recognize_google(audio)
        st.session_state.user_prompt = voice_query
        st.success(f"ЁЯУЭ Transcribed: {voice_query}")
    except sr.UnknownValueError:
        st.error("тЭМ Could not understand audio.")
    except sr.RequestError as e:
        st.error(f"тЭМ Speech recognition error: {e}")

# ------------------------------
# ЁЯФН Search & TTS
# ------------------------------
if st.button(TEXT[language]["search"]):
    if uploaded_files:
        create_vector_embeddings()
        if st.session_state.user_prompt:
            try:
                with st.spinner("ЁЯФО Searching and generating response..."):
                    document_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)
                    retriever = st.session_state.vector_store.as_retriever()
                    retriever_chain = create_retrieval_chain(retriever, document_chain)

                    start = time.process_time()
                    response = retriever_chain.invoke({"input": st.session_state.user_prompt})
                    elapsed = time.process_time() - start

                    # Response Card
                    answer_text = response.get('answer') or response.get('output') or response.get('result') or 'ЁЯдЦ No response generated.'
                    st.markdown(f"<h2>{TEXT[language]['response']}</h2>", unsafe_allow_html=True)
                    st.markdown(f"<div class='response-card'>{answer_text}</div>", unsafe_allow_html=True)
                    st.caption(f"тП▒я╕П Response time: {elapsed:.2f} seconds")

                    st.session_state.last_answer = answer_text

                    # TTS
                    tts = gTTS(answer_text, lang="en" if language=="English" else "hi")
                    audio_bytes_io = BytesIO()
                    tts.write_to_fp(audio_bytes_io)
                    audio_bytes_io.seek(0)
                    b64 = base64.b64encode(audio_bytes_io.read()).decode()
                    st.markdown(f"<audio autoplay style='display:none;'><source src='data:audio/mp3;base64,{b64}' type='audio/mp3'></audio>", unsafe_allow_html=True)

                    # Chat History
                    st.session_state.chat_history.append({
                        "question": st.session_state.user_prompt,
                        "answer": answer_text,
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    })

                    # Similarity Docs
                    with st.expander(TEXT[language]["similarity"]):
                        context_docs = response.get("context", [])
                        if context_docs:
                            for i, doc in enumerate(context_docs):
                                st.markdown(f"**Document {i+1}:**")
                                st.write(doc.page_content)
                                st.markdown("---")
                        else:
                            st.info("ЁЯУД No relevant documents found. Answering from general knowledge.")
            except Exception as e:
                st.error(f"{TEXT[language]['retrieval_error']} {e}")
        else:
            st.warning(TEXT[language]["query_warning"])
    else:
        st.warning(TEXT[language]["upload_warning"])

# ------------------------------
# ЁЯЧВя╕П Sidebar Chat History
# ------------------------------
with st.sidebar:
    st.markdown("### ЁЯЧВя╕П Chat History")
    if st.session_state.chat_history:
        for i, chat in enumerate(reversed(st.session_state.chat_history), 1):
            with st.expander(f"Q{i}: {chat['question']}"):
                st.markdown(f"ЁЯХТ {chat['timestamp']}")
                st.markdown(f"**Answer:** {chat['answer']}")
    else:
        st.info("ЁЯТм No chat history yet.")

    if st.button(TEXT[language]["clear_history"]):
        st.session_state.chat_history = []
        st.success("тЬЕ Chat history cleared.")

# ------------------------------
# ЁЯз╛ Footer
# ------------------------------
st.markdown(f"<div class='footer'>{TEXT[language]['footer']}</div>", unsafe_allow_html=True)
